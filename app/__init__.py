from dotenv import load_dotenv
load_dotenv()
# app/__init__.py
import os
import re
import json
import logging
from datetime import datetime, timezone, timedelta
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any

import markdown as md
import bleach
import redis as redis_lib
from rq import Queue

from flask import (
    Flask, Blueprint, render_template, request, jsonify, abort,
    current_app, redirect, url_for
)
from flask_wtf.csrf import CSRFProtect, CSRFError
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from flask_login import LoginManager, login_required, current_user
from flask_talisman import Talisman
from flask_migrate import Migrate
from flask_bcrypt import Bcrypt

from .models import db, User, Conversation, Message, Announcement, ResearchJob

logger = logging.getLogger("gemini_chat_app")

# ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã®åˆ¤å®š
USE_MOCK = os.getenv("USE_MOCK_GEMINI", "false").lower() == "true"
if USE_MOCK:
    from services.gemini_client_mock import GeminiClient, GeminiFallbackError
    logger.warning("ğŸ”§ Using MOCK Gemini client (development mode)")
else:
    # HTTPç‰ˆã‚’ä½¿ç”¨ï¼ˆPython SDKã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå•é¡Œã‚’å›é¿ï¼‰
    from services.gemini_client_http import GeminiClient, GeminiFallbackError
    logger.info("Using HTTP-based Gemini client")

from services.search import SearchClient, SearchError

# ===============================
# Markdown/XSS Safe Renderer
# ===============================
_ALLOWED_TAGS = set(bleach.sanitizer.ALLOWED_TAGS).union({
    "p", "br", "pre", "code", "blockquote",
    "ul", "ol", "li", "strong", "em",
    "h1", "h2", "h3", "h4",
    "table", "thead", "tbody", "tr", "th", "td"
})
_ALLOWED_ATTRS = {"a": ["href", "title", "rel", "target"]}
_ALLOWED_PROTOCOLS = ["http", "https", "mailto"]


def _linkify_callback(attrs, new=False):
    href_key = (None, "href")
    if href_key not in attrs:
        return attrs
    attrs[(None, "rel")] = "nofollow noopener noreferrer"
    attrs[(None, "target")] = "_blank"
    return attrs


def render_markdown_safe(text: str) -> str:
    if not text:
        return ""
    html = md.markdown(
        text,
        extensions=["fenced_code", "tables", "sane_lists", "nl2br"]
    )
    try:
        html = bleach.linkify(
            html, callbacks=[_linkify_callback], skip_tags=["code", "pre"], parse_email=True
        )
    except Exception as e:
        logger.warning(f"bleach.linkify failed, fallback without linkify: {e}")
    clean = bleach.clean(
        html, tags=_ALLOWED_TAGS, attributes=_ALLOWED_ATTRS,
        protocols=_ALLOWED_PROTOCOLS, strip=True
    )
    return clean


def clean_and_shorten_title(text: str, max_length: int = 18) -> str:
    if not text:
        return "ä¼šè©±"
    title = re.sub(r"[\r\n\t]+", " ", str(text)).strip()
    for ch in ['ã€Œ', 'ã€', '"', "'", 'ã€‚', 'ã€', 'ï¼š', ':', '|', '/', '\\', 'ã€€']:
        title = title.replace(ch, "")
    title = re.sub(r"\s+", " ", title)
    if len(title) > max_length:
        title = title[:max_length - 1] + "â€¦"
    return title.strip() or "ä¼šè©±"


# ===============================
# Helper: Summarizer selection
# ===============================
from typing import List, Dict, Any


def _summarize_with_citations(gc, query: str, results: List[Dict[str, Any]], requested_model: str = "") -> Dict[str, Any]:
    """Prefer enriched summarizer if available, fallback to default.

    This allows HTTP client to use enriched_content-aware prompt without
    changing the Python client which already handles enrichment internally.
    """
    try:
        if hasattr(gc, "summarize_with_citations_enriched"):
            return gc.summarize_with_citations_enriched(query, results, requested_model)
        return gc.summarize_with_citations(query, results, requested_model)
    except Exception:
        # Last resort: fall back to default method
        return gc.summarize_with_citations(query, results, requested_model)


# ===============================
# Helpers: Redis availability
# ===============================
def choose_redis_url_or_memory() -> tuple[str, bool]:
    """
    REDIS_URL ãŒä½¿ãˆã‚Œã°ãã‚Œã‚’è¿”ã™ã€‚æ¥ç¶šä¸å¯ãªã‚‰ ('memory://', False) ã‚’è¿”ã™ã€‚
    Render ã®ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—æ™‚ã« Redis ãŒé…å»¶èµ·å‹•ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€
    é•·ã‚ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ5ç§’ï¼‰ã‚’è¨­å®šã€‚
    """
    redis_url = os.getenv("REDIS_URL") or os.getenv("VALKEY_URL")
    if not redis_url:
        logger.info("REDIS_URL not set -> using memory storage for limiter and disabling RQ.")
        return "memory://", False

    try:
        # Render ã§ã®é…å»¶åˆæœŸåŒ–ã«å¯¾å¿œ: 5ç§’ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        conn = redis_lib.from_url(redis_url, socket_connect_timeout=5, socket_timeout=5)
        conn.ping()  # quick health check
        logger.info("Redis is available -> using Redis for limiter/RQ.")
        return redis_url, True
    except Exception as e:
        logger.warning(f"Redis check failed -> fallback to memory. reason={e}")
        return "memory://", False


# ===============================
# Flask Application Factory
# ===============================
def create_app() -> Flask:
    root = Path(__file__).resolve().parent.parent
    app = Flask(
        __name__,
        template_folder=str(root / "templates"),
        static_folder=str(root / "static"),
        instance_path=str(root / "instance"),
        instance_relative_config=True,
    )
    Path(app.instance_path).mkdir(parents=True, exist_ok=True)

    # Database configuration: PostgreSQL (production) or SQLite (development)
    database_url = os.getenv("DATABASE_URL")
    if database_url:
        # Render provides DATABASE_URL, but we need to handle postgres:// -> postgresql://
        if database_url.startswith("postgres://"):
            database_url = database_url.replace("postgres://", "postgresql://", 1)
        sqlalchemy_database_uri = database_url
    else:
        # Development: use SQLite
        db_path = Path(app.instance_path) / "database.db"
        sqlalchemy_database_uri = f"sqlite:///{db_path}"

    # SECRET_KEY validation
    secret_key = os.getenv("SECRET_KEY")
    if not secret_key:
        # Development fallback
        if os.getenv("FLASK_ENV") == "development" or not database_url:
            secret_key = "dev-secret-key-change-in-production"
            logger.warning("âš ï¸  Using development SECRET_KEY. Set SECRET_KEY environment variable in production!")
        else:
            raise RuntimeError("SECRET_KEY environment variable must be set in production!")

    app.config.update(
        SECRET_KEY=secret_key,
        SQLALCHEMY_DATABASE_URI=sqlalchemy_database_uri,
        SQLALCHEMY_TRACK_MODIFICATIONS=False,
        SESSION_COOKIE_SECURE=os.getenv("SESSION_COOKIE_SECURE", "true").lower() == "true",
        SESSION_COOKIE_HTTPONLY=os.getenv("SESSION_COOKIE_HTTPONLY", "true").lower() == "true",
        SESSION_COOKIE_SAMESITE=os.getenv("SESSION_COOKIE_SAMESITE", "Lax"),
        PERMANENT_SESSION_LIFETIME=int(os.getenv("PERMANENT_SESSION_LIFETIME", 604800)),
    )

    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ï¼ˆReferrer å¯¾ç­–ãƒ»HTTPS æ¨å¥¨ï¼‰
    # ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒã§ã¯ force_https ã‚’ç„¡åŠ¹åŒ–
    force_https = os.getenv("FORCE_HTTPS", "false").lower() == "true"
    Talisman(
        app,
        content_security_policy=None,
        referrer_policy="strict-origin-when-cross-origin",
        force_https=force_https,
    )

    # CSRF
    CSRFProtect(app)

    # Bcrypt
    bcrypt = Bcrypt(app)
    app.extensions['bcrypt'] = bcrypt

    # Limiter: RedisãŒç„¡ã‘ã‚Œã°memory://ã¸è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    limiter_storage_uri, redis_ok = choose_redis_url_or_memory()
    limiter = Limiter(
        key_func=get_remote_address,
        default_limits=["100/minute"],
        storage_uri=limiter_storage_uri,
    )
    limiter.init_app(app)

    # RQï¼ˆRedisã‚­ãƒ¥ãƒ¼ï¼‰: RedisãŒOKã®ã¨ãã ã‘æœ‰åŠ¹åŒ–
    if redis_ok:
        try:
            # Render ã§ã®é…å»¶åˆæœŸåŒ–ã«å¯¾å¿œ: 5ç§’ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            rq_conn = redis_lib.from_url(
                os.getenv("REDIS_URL") or os.getenv("VALKEY_URL"),
                socket_connect_timeout=5,
                socket_timeout=5
            )
            rq_queue = Queue("default", connection=rq_conn, default_timeout=180)
            app.extensions["rq_queue"] = rq_queue
            logger.info("RQ queue initialized successfully")
        except Exception as e:
            logger.warning(f"RQ init failed -> disable queue. reason={e}")
            app.extensions["rq_queue"] = None
    else:
        app.extensions["rq_queue"] = None

    # DB + Migrate
    db.init_app(app)
    Migrate(app, db)

    # ãƒ­ã‚°ã‚¤ãƒ³
    login_manager = LoginManager(app)
    login_manager.login_view = "auth.login"

    @login_manager.user_loader
    def load_user(user_id: str):
        return User.query.get(int(user_id))

    # å¤–éƒ¨APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«åã¯å­˜åœ¨ãƒã‚§ãƒƒã‚¯ä»˜ãã®å®Ÿè£…å´ã§ãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰
    app.extensions["gemini_client"] = GeminiClient(
        primary_model=os.getenv("DEFAULT_GEMINI_MODEL", "gemini-1.5-flash"),
        fallback_model=os.getenv("FALLBACK_GEMINI_MODEL", "gemini-1.5-pro"),
        api_key=os.getenv("GEMINI_API_KEY"),
    )
    app.extensions["search_client"] = SearchClient(
        provider=os.getenv("SEARCH_PROVIDER", "serpapi"),  # "google_cse" ã‹ã‚‰ "serpapi" ã«å¤‰æ›´
        env=os.environ
    )

    # Blueprintç™»éŒ²
    from .auth import auth_bp
    app.register_blueprint(auth_bp)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
    # æœ¬ç•ªç’°å¢ƒã§ã¯Flask-Migrateã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€é–‹ç™ºç’°å¢ƒã®ã¿è‡ªå‹•ä½œæˆ
    with app.app_context():
        if not database_url:  # SQLite (development)
            db.create_all()
            logger.info("Database tables created (development mode)")
        else:
            logger.info("Using Flask-Migrate for database management (production mode)")

    # ======================================================
    # Core Blueprint
    # ======================================================
    bp = Blueprint("core", __name__)

    def _json():
        try:
            return request.get_json(force=True)
        except Exception:
            abort(400, description="Invalid JSON")

    def _generate_summary_sync(conversation_id: int):
        """åŒæœŸçš„ã«è¦ç´„ã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆRedisãŒãªã„å ´åˆã®ä»£æ›¿ï¼‰"""
        try:
            conv = Conversation.query.get(conversation_id)
            if not conv:
                return

            gc: GeminiClient = current_app.extensions["gemini_client"]
            msgs = Message.query.filter_by(conversation_id=conversation_id).order_by(Message.id.asc()).all()
            # Gemini API: role ã¯ "user" ã¾ãŸã¯ "model" ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
            convo_dump = [{"role": "model" if m.sender == "assistant" else "user", "content": m.content} for m in msgs][-100:]

            analysis = gc.analyze_conversation(convo_dump)
            new_summary = (analysis.get("summary") or "").strip()

            if new_summary:
                conv.summary = new_summary
                # ã‚¿ã‚¤ãƒˆãƒ«ã¯è‡ªå‹•ç”Ÿæˆã—ãªã„ï¼ˆè¦ç´„ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ï¼‰
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰‹å‹•ã§ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®šã™ã‚‹ã“ã¨ã¯å¯èƒ½
                conv.updated_at = datetime.utcnow()
                db.session.commit()
                logger.info(f"âœ… Generated summary for conversation {conversation_id}")
        except Exception as e:
            logger.warning(f"Summary generation failed: {e}")

    def _admin_required():
        if not (current_user.is_authenticated and getattr(current_user, "is_admin", False)):
            abort(403, description="admin required")

    # ----------------- Health -----------------
    @bp.route("/healthz")
    def healthz():
        return jsonify(status="ok")

    # ----------------- Pages -----------------
    @bp.route("/")
    def index():
        if not current_user.is_authenticated:
            return redirect(url_for("auth.login"))
        return redirect(url_for("core.chat"))

    @bp.route("/chat")
    @login_required
    def chat():
        latest_announcement = Announcement.query.filter_by(is_active=True) \
            .order_by(Announcement.timestamp.desc()).first()
        return render_template(
            "chat.html",
            username=current_user.username,
            is_admin=bool(getattr(current_user, "is_admin", False)),
            announcement=latest_announcement
        )

    # ----------------- Admin Dashboard -----------------
    @bp.route("/admin_dashboard")
    @login_required
    def admin_dashboard():
        _admin_required()
        # Get users with conversation and message counts
        from sqlalchemy import func
        users = db.session.query(
            User,
            func.count(Conversation.id.distinct()).label('conversation_count'),
            func.count(Message.id).label('message_count')
        ).outerjoin(Conversation, User.id == Conversation.user_id)\
         .outerjoin(Message, Conversation.id == Message.conversation_id)\
         .group_by(User.id)\
         .order_by(User.id.asc())\
         .all()

        # Unpack query results
        users_with_stats = []
        for user, conv_count, msg_count in users:
            user.conversation_count = conv_count
            user.message_count = msg_count
            users_with_stats.append(user)

        conversations = db.session.query(Conversation).order_by(
            Conversation.is_pinned.desc(), Conversation.id.desc()
        ).limit(100).all()
        announcements = db.session.query(Announcement).order_by(
            Announcement.timestamp.desc().nullslast()
        ).all()
        return render_template(
            "admin_dashboard.html",
            users=users_with_stats, conversations=conversations, announcements=announcements
        )

    @bp.route("/admin/user/<int:user_id>")
    @login_required
    def user_detail(user_id: int):
        _admin_required()
        user = db.session.get(User, user_id)
        if not user:
            abort(404)

        # Get user statistics
        from sqlalchemy import func
        total_conversations = db.session.query(func.count(Conversation.id))\
            .filter(Conversation.user_id == user_id).scalar()
        total_messages = db.session.query(func.count(Message.id))\
            .join(Conversation, Message.conversation_id == Conversation.id)\
            .filter(Conversation.user_id == user_id).scalar()
        pinned_conversations = db.session.query(func.count(Conversation.id))\
            .filter(Conversation.user_id == user_id, Conversation.is_pinned == True).scalar()
        deep_research_jobs = db.session.query(func.count(ResearchJob.id))\
            .filter(ResearchJob.user_id == user_id).scalar()

        stats = {
            'total_conversations': total_conversations or 0,
            'total_messages': total_messages or 0,
            'pinned_conversations': pinned_conversations or 0,
            'deep_research_jobs': deep_research_jobs or 0
        }

        # Get recent conversations with message counts
        conversations = db.session.query(
            Conversation,
            func.count(Message.id).label('message_count')
        ).outerjoin(Message, Conversation.id == Message.conversation_id)\
         .filter(Conversation.user_id == user_id)\
         .group_by(Conversation.id)\
         .order_by(Conversation.updated_at.desc())\
         .limit(10).all()

        # Unpack and add message_count to conversations
        conversations_with_count = []
        for conv, msg_count in conversations:
            conv.message_count = msg_count
            conversations_with_count.append(conv)

        # Get recent research jobs
        research_jobs = db.session.query(ResearchJob)\
            .filter(ResearchJob.user_id == user_id)\
            .order_by(ResearchJob.id.desc())\
            .limit(10).all()

        return render_template(
            "user_detail.html",
            user=user,
            stats=stats,
            conversations=conversations_with_count,
            research_jobs=research_jobs
        )

    @bp.route("/admin/announcement/add", methods=["POST"])
    @login_required
    def add_announcement():
        _admin_required()
        msg = (request.form.get("message") or "").strip()
        is_active = bool(request.form.get("is_active"))
        if not msg:
            abort(400, description="message is required")
        a = Announcement(message=msg, is_active=is_active, timestamp=datetime.utcnow())
        db.session.add(a)
        db.session.commit()

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›è³‡æ–™ï¼ˆDeepResearch ãªã©ï¼‰ã‚’å–ã‚Šè¾¼ã‚€
        user_sources_raw = data.get("user_sources") or []
        user_sources: List[Dict[str, Any]] = []
        try:
            for src in user_sources_raw:
                if not isinstance(src, dict):
                    continue
                title = (src.get("title") or "ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›è³‡æ–™").strip()
                content = (src.get("content") or "").strip()
                chapter = (src.get("chapter") or "").strip()
                if not content:
                    continue
                user_sources.append({
                    "title": title,
                    "url": src.get("url") or f"user:{title}",
                    "snippet": content[:500],
                    "enriched_content": content,
                    "source": "user",
                    "chapter": chapter,
                })
        except Exception:
            user_sources = []
        return redirect(url_for("core.admin_dashboard"))

    @bp.route("/admin/announcement/<int:ann_id>/toggle", methods=["POST"])
    @login_required
    def toggle_announcement(ann_id: int):
        _admin_required()
        a = Announcement.query.get_or_404(ann_id)
        a.is_active = not bool(a.is_active)
        db.session.commit()
        return redirect(url_for("core.admin_dashboard"))

    @bp.route("/admin/announcement/<int:ann_id>/delete", methods=["POST"])
    @login_required
    def delete_announcement(ann_id: int):
        _admin_required()
        a = Announcement.query.get_or_404(ann_id)
        db.session.delete(a)
        db.session.commit()
        return redirect(url_for("core.admin_dashboard"))

    @bp.route("/admin/delete_user/<int:user_id>", methods=["POST"])
    @login_required
    def delete_user(user_id: int):
        _admin_required()
        user = User.query.get(user_id)
        if not user:
            abort(404)
        convs = Conversation.query.filter_by(user_id=user.id).all()
        for c in convs:
            Message.query.filter_by(conversation_id=c.id).delete()
            db.session.delete(c)
        db.session.delete(user)
        db.session.commit()
        return redirect(url_for("core.admin_dashboard"))

    @bp.route("/admin/delete_conversation/<int:cid>", methods=["POST"])
    @login_required
    def delete_conversation(cid: int):
        _admin_required()
        conv = Conversation.query.get(cid)
        if not conv:
            abort(404)
        Message.query.filter_by(conversation_id=cid).delete()
        db.session.delete(conv)
        db.session.commit()
        return redirect(url_for("core.admin_dashboard"))

    # ----------------- Conversations API -----------------
    @bp.route("/api/conversations", methods=["GET"])
    @login_required
    def list_conversations():
        q = (request.args.get("q") or "").strip().lower()
        items = Conversation.query.filter_by(user_id=current_user.id).order_by(
            Conversation.is_pinned.desc(), Conversation.id.desc()
        ).all()
        out = []
        for c in items:
            if q:
                hay = ((c.title or "") + " " + (c.summary or "")).lower()
                if q not in hay:
                    continue
            out.append({
                "id": c.id,
                "title": c.title,
                "summary": (c.summary or ""),
                "is_pinned": bool(c.is_pinned),
                "created_at": c.created_at.isoformat() if getattr(c, "created_at", None) else "",
            })
        return jsonify({"ok": True, "items": out})

    @bp.route("/api/conversations", methods=["POST"])
    @login_required
    def create_conversation():
        data = _json()
        title = (data.get("title") or f"æ–°ã—ã„ä¼šè©± {datetime.utcnow().strftime('%H:%M:%S')}").strip()
        conv = Conversation(title=title, user_id=current_user.id, is_pinned=False)
        db.session.add(conv)
        db.session.commit()
        return jsonify({"ok": True, "id": conv.id})

    @bp.route("/api/conversations/<int:cid>", methods=["PATCH"])
    @login_required
    def update_conversation(cid: int):
        conv = Conversation.query.filter_by(id=cid, user_id=current_user.id).first()
        if not conv:
            abort(404)
        data = _json()
        if "title" in data:
            t = (data.get("title") or "").strip()
            if t:
                conv.title = t
        if "is_pinned" in data:
            conv.is_pinned = bool(data.get("is_pinned"))
        db.session.commit()
        return jsonify({"ok": True})

    @bp.route("/api/conversations/<int:cid>", methods=["DELETE"])
    @login_required
    def remove_conversation(cid: int):
        conv = Conversation.query.filter_by(id=cid, user_id=current_user.id).first()
        if not conv:
            abort(404)
        Message.query.filter_by(conversation_id=cid).delete()
        db.session.delete(conv)
        db.session.commit()
        return jsonify({"ok": True})

    # ----------------- History (summaryä»˜ã) -----------------
    @bp.route("/api/history/<int:conversation_id>", methods=["GET"])
    @login_required
    def api_history(conversation_id: int):
        conv = Conversation.query.filter_by(id=conversation_id, user_id=current_user.id).first()
        if not conv and not getattr(current_user, "is_admin", False):
            abort(404)
        msgs = Message.query.filter_by(conversation_id=conversation_id).order_by(Message.id.asc()).all()
        data = [{
            "role": m.sender,
            "content": m.content,
            "html": render_markdown_safe(m.content),
            "created_at": m.created_at.isoformat()
        } for m in msgs]
        return jsonify({
            "ok": True,
            "messages": data,
            "summary": conv.summary or ""
        })

    # ----------------- Chat APIï¼ˆé®®åº¦ãƒ­ã‚¸ãƒƒã‚¯å†…è”µï¼‰ -----------------
    @bp.route("/api/chat", methods=["POST"])
    @login_required
    def api_chat():
        data = _json()
        msg = (data.get("message") or "").strip()
        if not msg:
            abort(400, description="message is required")

        cid = data.get("conversation_id")
        conv = Conversation.query.filter_by(id=cid, user_id=current_user.id).first() if cid else None
        if not conv:
            conv = Conversation(
                title=f"æ–°ã—ã„ä¼šè©± {datetime.utcnow().strftime('%H:%M:%S')}",
                user_id=current_user.id, is_pinned=False
            )
            db.session.add(conv)
            db.session.commit()
            cid = conv.id

        # ä¿å­˜ï¼ˆãƒ¦ãƒ¼ã‚¶ç™ºè©±ï¼‰
        db.session.add(Message(content=msg, sender="user", conversation_id=cid))
        db.session.commit()

        # æ›¸ç±è¦ç´„åˆ¤å®š â†’ æ›¸ç±å°‚ç”¨æ¤œç´¢ãƒ‘ã‚¹
        import re
        q_lower = msg.lower()

        # æ›¸ç±è¦ç´„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®æ¤œå‡º
        book_keywords = ["è¦ç´„", "ã¾ã¨ã‚", "å†…å®¹", "ã«ã¤ã„ã¦", "ç›®æ¬¡", "ç« "]
        has_book_request = any(kw in msg for kw in book_keywords) and any(kw in msg for kw in ["æœ¬", "æ›¸ç±", "è‘—æ›¸"])

        # æ—¥æœ¬èªå¼•ç”¨ç¬¦ã§å›²ã¾ã‚ŒãŸæ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¤œå‡º
        book_title_match = re.search(r'[ã€Œã€]([^ã€ã€]+)[ã€ã€]', msg)

        # æ˜ç¤ºçš„ãªæ›¸ç±åãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹: "å®‰å²¡å®šå­ å®Ÿè·µãƒ»è«–èªå¡¾"ï¼‰
        # ã¾ãŸã¯å¼•ç”¨ç¬¦å†…ã®ãƒ†ã‚­ã‚¹ãƒˆ
        if book_title_match or has_book_request:
            try:
                sc: SearchClient = current_app.extensions["search_client"]
                gc: GeminiClient = current_app.extensions["gemini_client"]

                # æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ã¨è‘—è€…åã®æŠ½å‡º
                author = None
                if book_title_match:
                    book_title = book_title_match.group(1).strip()
                    # è‘—è€…åã‚’æŠ½å‡ºï¼ˆ"è‘—è€…å ã‚¿ã‚¤ãƒˆãƒ«"ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
                    author_title_pattern = r'^([^\s]+(?:\s+[^\s]+)?)\s+(.+)$'
                    author_match = re.search(author_title_pattern, book_title)
                    if author_match and len(author_match.group(1)) <= 10:  # è‘—è€…åã¯é€šå¸¸10æ–‡å­—ä»¥å†…
                        potential_author = author_match.group(1)
                        potential_title = author_match.group(2)
                        # è‘—è€…åã‚‰ã—ã„å ´åˆã®ã¿åˆ†å‰²
                        if any(c in potential_author for c in ['å®šå­', 'å¤ªéƒ', 'èŠ±å­', 'ä¸€éƒ']) or \
                           potential_author.count(' ') == 0:
                            author = potential_author
                            book_title = potential_title
                else:
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¨æ¸¬
                    # "ã«ã¤ã„ã¦" ã®å‰ã®éƒ¨åˆ†ã‚’æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦æ‰±ã†
                    title_pattern = r'(.+?)(?:ã«ã¤ã„ã¦|ã®æœ¬|ã®æ›¸ç±|ã‚’è¦ç´„|ã®ã¾ã¨ã‚)'
                    title_match = re.search(title_pattern, msg)
                    if title_match:
                        full_text = title_match.group(1).strip()
                        # ä¸è¦ãªæ¥é ­è¾ã‚’å‰Šé™¤
                        full_text = re.sub(r'^(æ¬¡ã®|ä»¥ä¸‹ã®|ã“ã®)?(æœ¬|æ›¸ç±|è‘—æ›¸)?[:ï¼š]?\s*', '', full_text)

                        # è‘—è€…åã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’åˆ†å‰²ï¼ˆ"è‘—è€…å ã‚¿ã‚¤ãƒˆãƒ«"ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
                        parts = full_text.split(None, 1)  # æœ€åˆã®ç©ºç™½ã§åˆ†å‰²
                        if len(parts) == 2 and len(parts[0]) <= 10:
                            author = parts[0]
                            book_title = parts[1]
                        else:
                            book_title = full_text
                    else:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¨ä½“ã‹ã‚‰æ›¸ç±åã‚’æŠ½å‡ºã§ããªã„å ´åˆã¯é€šå¸¸ãƒ‘ã‚¹ã¸
                        raise ValueError("æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")

                # ç›®æ¬¡ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                toc_pattern = r'(åºç« |ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« |çµ‚ç« |ç¬¬\d+ç« )'
                has_toc = bool(re.search(toc_pattern, msg))

                if has_toc:
                    # ç›®æ¬¡éƒ¨åˆ†ã‚’æŠ½å‡º
                    toc_lines = [line.strip() for line in msg.split('\n') if re.search(toc_pattern, line)]
                    table_of_contents = '\n'.join(toc_lines)
                else:
                    table_of_contents = "ï¼ˆç›®æ¬¡æƒ…å ±ãªã—ï¼‰"

                # æ›¸ç±å°‚ç”¨æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆè‘—è€…åã‚‚æ¸¡ã™ï¼‰
                logger.info(f"Book search request detected: title='{book_title}', author='{author}'")
                results = sc.search_book_v2(book_title, author=author, top_k=10)
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›è³‡æ–™ãŒã‚ã‚Œã°å…ˆé ­ã«ãƒãƒ¼ã‚¸ï¼ˆç°¡æ˜“é‡è¤‡æ’é™¤ï¼‰
                try:
                    if user_sources:
                        seen = set((r.get("url") or r.get("link") or r.get("info_link") or "") for r in results)
                        merged = []
                        for r in user_sources:
                            u = r.get("url") or ""
                            if u not in seen:
                                merged.append(r)
                                seen.add(u)
                        merged.extend(results)
                        results = merged
                except Exception:
                    pass

                if not results:
                    # æ¤œç´¢çµæœãŒ0ä»¶ã®å ´åˆ
                    reply = f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚æ›¸ç±ã€Œ{book_title}ã€ã«é–¢ã™ã‚‹ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ›¸ç±åã‚’ç¢ºèªã®ä¸Šã€å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
                    db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
                    db.session.commit()
                else:
                    # æ›¸ç±å°‚ç”¨è¦ç´„ã‚’å®Ÿè¡Œ
                    if has_toc and table_of_contents:
                        summary = gc.summarize_book_with_toc(
                            book_title,
                            table_of_contents,
                            results,
                            (data.get("model") or "").strip()
                        )
                    else:
                        # ç›®æ¬¡ãŒãªã„å ´åˆã¯é€šå¸¸ã®è¦ç´„
                        query_for_summary = f"æ›¸ç±ã€Œ{book_title}ã€ã®å†…å®¹ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚å‡ºç‰ˆç¤¾ã‚„æ›¸è©•ã‚µã‚¤ãƒˆã®æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚"
                        summary = _summarize_with_citations(gc, query_for_summary, results, (data.get("model") or "").strip())

                    reply = summary.get("answer") or summary.get("summary") or summary.get("text") or "è¦ç´„ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
                    db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
                    db.session.commit()

                # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã§ã‚µãƒãƒªãƒ¼ãƒ»ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
                q = current_app.extensions.get("rq_queue")
                if q:
                    q.enqueue("services.tasks.generate_summary_and_title", cid, job_timeout=180)
                else:
                    _generate_summary_sync(cid)

                return jsonify({
                    "ok": True, "reply": reply,
                    "reply_html": render_markdown_safe(reply),
                    "conversation_id": cid
                })
            except SearchError as e:
                logger.error(f"Book search path failed due to SearchError: {e}")
                reply = f"æ›¸ç±æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­å®šï¼ˆAPIã‚­ãƒ¼ãªã©ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼: {e}"
                db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
                db.session.commit()
                return jsonify({"ok": True, "reply": reply, "reply_html": render_markdown_safe(reply), "conversation_id": cid})
            except Exception as e:
                logger.error(f"Book search path failed unexpectedly: {e}")
                # äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã§ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã›ãšã€ã‚¨ãƒ©ãƒ¼ã‚’é€šçŸ¥ã™ã‚‹
                reply = f"æ›¸ç±æ¤œç´¢ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
                db.session.commit()
                return jsonify({"ok": True, "reply": reply, "reply_html": render_markdown_safe(reply), "conversation_id": cid})

        # å¤©æ°—ï¼ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ¤å®š â†’ æ¤œç´¢å„ªå…ˆ
        is_weather = any(w in msg for w in ["å¤©æ°—", "å¤©å€™", "äºˆå ±"]) or "weather" in q_lower or "forecast" in q_lower
        is_news = any(w in msg for w in ["ãƒ‹ãƒ¥ãƒ¼ã‚¹", "é€Ÿå ±"]) or "news" in q_lower or "headline" in q_lower

        if is_weather or is_news:
            try:
                JST = timezone(timedelta(hours=9))
                today = datetime.now(JST)
                jp_full = f"{today.year}å¹´{today.month}æœˆ{today.day}æ—¥"
                iso1 = today.strftime("%Y-%m-%d")

                sc: SearchClient = current_app.extensions["search_client"]
                gc: GeminiClient = current_app.extensions["gemini_client"]

                site_bias = (
                    "site:tenki.jp OR site:weather.yahoo.co.jp OR site:jma.go.jp OR site:weather.com"
                    if is_weather else
                    "site:news.yahoo.co.jp OR site:www3.nhk.or.jp OR site:asahi.com OR site:mainichi.jp OR site:nikkei.com"
                )
                query1 = f"{msg} {jp_full} {site_bias}"
                results = sc.search(query1, top_k=10, recency_days=1)
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›è³‡æ–™ã‚’ãƒãƒ¼ã‚¸ï¼ˆä»»æ„ï¼‰
                try:
                    if user_sources:
                        seen = set((r.get("url") or r.get("link") or r.get("info_link") or "") for r in results)
                        merged = []
                        for r in user_sources:
                            u = r.get("url") or ""
                            if u not in seen:
                                merged.append(r)
                                seen.add(u)
                        merged.extend(results)
                        results = merged
                except Exception:
                    pass

                guard = f"ä»Šæ—¥ã¯ {iso1}ï¼ˆJSTï¼‰ã§ã™ã€‚ä»Šæ—¥ã®æƒ…å ±ã®ã¿æ¡ç”¨ã—ã¦ãã ã•ã„ã€‚éå»æ—¥ä»˜ã¯é™¤å¤–ã€‚"
                composed = guard + "\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›: " + msg
                summary = _summarize_with_citations(gc, composed, results, (data.get("model") or "").strip())

                reply = summary.get("answer") or summary.get("summary") or summary.get("text") or "æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
                db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
                db.session.commit()

                # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã§ã‚µãƒãƒªãƒ¼ãƒ»ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆï¼ˆRedisãŒãªã‘ã‚Œã°åŒæœŸå®Ÿè¡Œï¼‰
                q = current_app.extensions.get("rq_queue")
                if q:
                    q.enqueue("services.tasks.generate_summary_and_title", cid, job_timeout=180)
                else:
                    # RedisãŒãªã„å ´åˆã¯åŒæœŸçš„ã«ç”Ÿæˆ
                    _generate_summary_sync(cid)

                return jsonify({
                    "ok": True, "reply": reply,
                    "reply_html": render_markdown_safe(reply),
                    "conversation_id": cid
                })
            except SearchError as e:
                logger.error(f"News/Weather search path failed due to SearchError: {e}")
                reply = f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»å¤©æ°—æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­å®šï¼ˆAPIã‚­ãƒ¼ãªã©ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼: {e}"
                db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
                db.session.commit()
                return jsonify({"ok": True, "reply": reply, "reply_html": render_markdown_safe(reply), "conversation_id": cid})
            except Exception as e:
                logger.error(f"News/Weather search path failed unexpectedly: {e}")
                reply = f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»å¤©æ°—æ¤œç´¢ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
                db.session.commit()
                return jsonify({"ok": True, "reply": reply, "reply_html": render_markdown_safe(reply), "conversation_id": cid})

        # é€šå¸¸ãƒãƒ£ãƒƒãƒˆ
        gc: GeminiClient = current_app.extensions["gemini_client"]
        try:
            # Gemini API: role ã¯ "user" ã¾ãŸã¯ "model" ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
            # "assistant" ã¯ "model" ã«å¤‰æ›
            history = [{"role": "model" if m.sender == "assistant" else "user", "content": m.content}
                       for m in Message.query.filter_by(conversation_id=cid).order_by(Message.id.asc()).all()][-50:]
            reply, used = gc.chat(history, msg, requested_model=(data.get("model") or "").strip())
        except GeminiFallbackError as e:
            return jsonify({"ok": False, "error": str(e)}), 502

        db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
        db.session.commit()

        # åŒæœŸçš„ã«è¦ç´„ã‚’ç”Ÿæˆ
        _generate_summary_sync(cid)

        return jsonify({
            "ok": True,
            "reply": reply,
            "reply_html": render_markdown_safe(reply),
            "model": used,
            "conversation_id": cid
        })

    # ----------------- Search + Summarizeï¼ˆç‹¬ç«‹APIï¼‰ -----------------
    @bp.route("/api/search_summarize", methods=["POST"])
    @login_required
    def api_search_summarize():
        data = _json()
        query = (data.get("query") or "").strip()
        if not query:
            abort(400, description="query is required")

        # ä¼šè©±IDã‚’å–å¾—ã¾ãŸã¯ä½œæˆ
        cid = data.get("conversation_id")
        conv = Conversation.query.filter_by(id=cid, user_id=current_user.id).first() if cid else None
        if not conv:
            conv = Conversation(
                title=f"æ–°ã—ã„ä¼šè©± {datetime.utcnow().strftime('%H:%M:%S')}",
                user_id=current_user.id, is_pinned=False
            )
            db.session.add(conv)
            db.session.commit()
            cid = conv.id

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
        db.session.add(Message(content=query, sender="user", conversation_id=cid))
        db.session.commit()

        JST = timezone(timedelta(hours=9))
        today = datetime.now(JST)
        jp_full = f"{today.year}å¹´{today.month}æœˆ{today.day}æ—¥"
        iso1 = today.strftime("%Y-%m-%d")

        sc: SearchClient = current_app.extensions["search_client"]
        gc: GeminiClient = current_app.extensions["gemini_client"]

        try:
            # ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šï¼ˆå„ªå…ˆé †ä½: æ™‚é–“ä¾å­˜ > æ™‚é–“éä¾å­˜ > æ—¥ä»˜ã‚¯ã‚¨ãƒªï¼‰
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›è³‡æ–™ï¼ˆDeepResearch ãªã©ï¼‰
            user_sources_raw = data.get("user_sources") or []
            user_sources: List[Dict[str, Any]] = []
            try:
                for src in user_sources_raw:
                    if not isinstance(src, dict):
                        continue
                    title = (src.get("title") or "ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›è³‡æ–™").strip()
                    content = (src.get("content") or "").strip()
                    chapter = (src.get("chapter") or "").strip()
                    if not content:
                        continue
                    user_sources.append({
                        "title": title,
                        "url": src.get("url") or f"user:{title}",
                        "snippet": content[:500],
                        "enriched_content": content,
                        "source": "user",
                        "chapter": chapter,
                    })
            except Exception:
                user_sources = []

            q_lower = query.lower()

            # æ™‚é–“ä¾å­˜ã‚¯ã‚¨ãƒª: æœ€æ–°æƒ…å ±ãŒå¿…è¦ï¼ˆæœ€å„ªå…ˆï¼‰
            time_sensitive_keywords = ["å¤©æ°—", "å¤©å€™", "äºˆå ±", "ãƒ‹ãƒ¥ãƒ¼ã‚¹", "é€Ÿå ±", "æœ€æ–°", "weather", "forecast", "news", "latest"]
            is_time_sensitive = any(kw in q_lower for kw in time_sensitive_keywords)

            # æ™‚é–“éä¾å­˜ã‚¯ã‚¨ãƒª: æœ¬ã€æ­´å²ã€æ¦‚å¿µã€å®šç¾©ãªã©
            timeless_keywords = ["æœ¬", "æ›¸ç±", "è‘—è€…", "book", "æ­´å²", "history", "ã¨ã¯", "æ„å‘³", "å®šç¾©", "definition",
                               "æ–¹æ³•", "how to", "ã‚„ã‚Šæ–¹", "æ¦‚è¦", "è¦ç´„", "summary", "è§£èª¬", "explanation"]
            is_timeless = any(kw in q_lower for kw in timeless_keywords) and not is_time_sensitive

            # æ—¥ä»˜ã‚¯ã‚¨ãƒª: ä»Šæ—¥ã®æ—¥ä»˜ã‚’èã„ã¦ã„ã‚‹ï¼ˆä»–ã«è©²å½“ã—ãªã„å ´åˆã®ã¿ï¼‰
            date_keywords = ["æ—¥ä»˜", "ä½•æ—¥"]
            is_date_query = any(kw in q_lower for kw in date_keywords) and not is_time_sensitive and not is_timeless

            # é®®åº¦ãƒ•ã‚£ãƒ«ã‚¿ã‚’å‹•çš„ã«è¨­å®š
            if is_time_sensitive:
                recency = 1  # å¤©æ°—ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹: éå»1æ—¥
            elif is_timeless:
                recency = None  # æ™‚é–“éä¾å­˜: ãƒ•ã‚£ãƒ«ã‚¿ãªã—
            else:
                recency = 7  # ãã®ä»–: éå»7æ—¥

            # æ¤œç´¢ã®å®Ÿè¡Œï¼ˆæœ¬ã®å ´åˆã¯è¤‡æ•°ã‚¯ã‚¨ãƒªã§æ¤œç´¢ï¼‰
            results = []
            if is_timeless and any(kw in q_lower for kw in ["æœ¬", "æ›¸ç±", "book"]):
                # æ›¸ç±åã‚’æŠ½å‡ºï¼ˆã€Œã®æœ¬ã€ã€Œã®æ›¸ç±ã€ãªã©ã‚’å‰Šé™¤ï¼‰
                book_name = query
                for suffix in ["ã®æœ¬ã®æƒ…å ±ã‚’è¦ç´„ã—ã¦", "ã®æœ¬ã‚’è¦ç´„ã—ã¦", "ã®æ›¸ç±ã‚’è¦ç´„ã—ã¦", "ã®è¦ç´„", "ã«ã¤ã„ã¦", "ã®æƒ…å ±"]:
                    book_name = book_name.replace(suffix, "")
                book_name = book_name.strip()

                # æœ¬ã®æƒ…å ±æ¤œç´¢: è¤‡æ•°ã®ã‚¯ã‚¨ãƒªã§æ¤œç´¢ã—ã€çµæœã‚’ãƒãƒ¼ã‚¸
                book_queries = [
                    f'"{book_name}"',  # å®Œå…¨ä¸€è‡´æ¤œç´¢
                    f"{book_name} æ›¸è©•",
                    f"{book_name} å†…å®¹ ç›®æ¬¡",
                    f"{book_name} ãƒ¬ãƒ“ãƒ¥ãƒ¼ æ„Ÿæƒ³",
                    f"{book_name} è‘—è€…",
                ]

                seen_urls = set()
                for bq in book_queries:
                    try:
                        partial = sc.search(bq, top_k=5, recency_days=recency)
                        for item in partial:
                            url = item.get("url", "")
                            if url and url not in seen_urls:
                                seen_urls.add(url)
                                results.append(item)
                                if len(results) >= 15:  # æœ€å¤§15ä»¶
                                    break
                    except Exception as e:
                        logger.warning(f"Book search query failed: {bq}, error: {e}")
                        continue
                    if len(results) >= 15:
                        break
            elif is_date_query:
                results = sc.search(query, top_k=5, recency_days=recency)
            else:
                # é€šå¸¸ã®æ¤œç´¢
                search_query = query if (is_date_query or is_timeless) else f"{query} {jp_full}"
                top_k = int(data.get("top_k") or 10)
                results = sc.search(search_query, top_k=top_k, recency_days=recency)

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›è³‡æ–™ãŒã‚ã‚Œã°å…ˆé ­ã«ãƒãƒ¼ã‚¸
            try:
                if 'user_sources' in locals() and user_sources:
                    seen = set((r.get("url") or r.get("link") or r.get("info_link") or "") for r in results)
                    merged = []
                    for r in user_sources:
                        u = r.get("url") or ""
                        if u not in seen:
                            merged.append(r)
                            seen.add(u)
                    merged.extend(results)
                    results = merged
            except Exception:
                pass
        except SearchError as e:
            logger.error(f"Search/Summarize path failed due to SearchError: {e}")
            reply = f"Webæ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­å®šï¼ˆAPIã‚­ãƒ¼ãªã©ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼: {e}"
            db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
            db.session.commit()
            return jsonify({"ok": True, "answer": reply, "citations": []})

        # æ¤œç´¢çµæœãŒå°‘ãªã„å ´åˆã®è­¦å‘Š
        if len(results) == 0:
            error_msg = "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ›¸ç±åã‚’æ­£ç¢ºã«å…¥åŠ›ã™ã‚‹ã‹ã€åˆ¥ã®æ¤œç´¢æ–¹æ³•ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚"
            db.session.add(Message(content=error_msg, sender="assistant", conversation_id=cid))
            db.session.commit()
            return jsonify({"ok": True, "answer": error_msg, "citations": []})

        logger.info(f"Found {len(results)} search results for query: {query}")

        try:
            # ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            if is_date_query:
                guard = f"ä»Šæ—¥ã®æ—¥ä»˜ã¯ {iso1}ï¼ˆ{jp_full}ã€JSTï¼‰ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œä»Šæ—¥ã®æ—¥ä»˜ã€ã‚’å°‹ã­ã¦ã„ã‚‹å ´åˆã€ã“ã®æ—¥ä»˜ã‚’ç›´æ¥ç­”ãˆã¦ãã ã•ã„ã€‚"
            elif is_time_sensitive:
                guard = f"ä»Šæ—¥ã¯ {iso1}ï¼ˆ{jp_full}ã€JSTï¼‰ã§ã™ã€‚æœ€æ–°ã®æƒ…å ±ï¼ˆéå»24æ™‚é–“ä»¥å†…ï¼‰ã‚’å„ªå…ˆã—ã¦æ¡ç”¨ã—ã¦ãã ã•ã„ã€‚"
            elif is_timeless:
                # æœ¬ã®æ¤œç´¢ã®å ´åˆã¯å°‚ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                if any(kw in q_lower for kw in ["æœ¬", "æ›¸ç±", "book"]):
                    guard = (
                        f"å‚è€ƒæ—¥: {iso1}ã€‚ä»¥ä¸‹ã¯æ›¸ç±ã«é–¢ã™ã‚‹æƒ…å ±ã®è¦ç´„ã‚¿ã‚¹ã‚¯ã§ã™ã€‚\n\n"
                        f"**æ¤œç´¢çµæœæ•°: {len(results)}ä»¶**\n\n"
                        "**é‡è¦ãªæŒ‡ç¤º:**\n"
                        "1. æä¾›ã•ã‚ŒãŸæ¤œç´¢çµæœã‚’å¾¹åº•çš„ã«åˆ†æã—ã€æ›¸ç±ã«é–¢ã™ã‚‹æƒ…å ±ã‚’å¯èƒ½ãªé™ã‚ŠæŠ½å‡ºã—ã¦ãã ã•ã„\n"
                        "2. æ›¸ç±ã®ã‚¿ã‚¤ãƒˆãƒ«ã€è‘—è€…ã€å‡ºç‰ˆç¤¾ã€ãƒ†ãƒ¼ãƒã€æ¦‚è¦ãªã©ã®åŸºæœ¬æƒ…å ±ã‚’ç‰¹å®šã—ã¦ãã ã•ã„\n"
                        "3. æ›¸è©•ã‚µã‚¤ãƒˆã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€Amazonã€èª­æ›¸ãƒ¡ãƒ¼ã‚¿ãƒ¼ãªã©ã®æƒ…å ±ãŒã‚ã‚Œã°æ´»ç”¨ã—ã¦ãã ã•ã„\n"
                        "4. ç›®æ¬¡ã‚„ç« ç«‹ã¦ãŒåˆ†ã‹ã‚‹å ´åˆã¯ã€å„ç« ã®å†…å®¹ã‚’æ¨æ¸¬ã‚‚å«ã‚ã¦èª¬æ˜ã—ã¦ãã ã•ã„\n"
                        "5. è‘—è€…ã®çµŒæ­´ã‚„å°‚é–€åˆ†é‡ã‹ã‚‰ã€æœ¬ã®å†…å®¹ã‚„æ„å›³ã‚’æ¨æ¸¬ã—ã¦ãã ã•ã„\n"
                        "6. ç›´æ¥çš„ãªæƒ…å ±ãŒãªã„éƒ¨åˆ†ã§ã‚‚ã€é–¢é€£æƒ…å ±ã‹ã‚‰åˆç†çš„ã«æ¨æ¸¬ã§ãã‚‹å†…å®¹ã¯å«ã‚ã¦ãã ã•ã„\n"
                        "7. æ¤œç´¢çµæœãŒæ–­ç‰‡çš„ã§ã‚‚ã€å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã‚’çµ±åˆã—ã¦æœ‰ç”¨ãªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„\n"
                        "8. ã€Œä¸æ˜ã€ã¨ã™ã‚‹å‰ã«ã€æ¤œç´¢çµæœã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ã“ã¨ã‚’æœ€å¤§é™æ´»ç”¨ã—ã¦ãã ã•ã„\n"
                        "9. æ›¸ç±ã®å¯¾è±¡èª­è€…å±¤ã‚„ã€ã©ã®ã‚ˆã†ãªå ´é¢ã§å½¹ç«‹ã¤ã‹ã‚‚è€ƒå¯Ÿã—ã¦ãã ã•ã„\n\n"
                        "**æ³¨æ„:** æ¤œç´¢çµæœã«ç›´æ¥çš„ãªæ›¸ç±æƒ…å ±ãŒãªã„å ´åˆã§ã‚‚ã€è«¦ã‚ãšã«é–¢é€£ã™ã‚‹æƒ…å ±ã‹ã‚‰æ¨æ¸¬ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚"
                    )
                else:
                    guard = f"å‚è€ƒæ—¥: {iso1}ï¼ˆ{jp_full}ã€JSTï¼‰ã€‚ä»¥ä¸‹ã¯æ™‚é–“ã«ä¾å­˜ã—ãªã„æƒ…å ±ã®è¦ç´„ã§ã™ã€‚æ¤œç´¢çµæœã‹ã‚‰ä¿¡é ¼æ€§ã®é«˜ã„æƒ…å ±ã‚’ç·åˆçš„ã«åˆ†æã—ã¦ãã ã•ã„ã€‚"
            else:
                guard = f"ä»Šæ—¥ã¯ {iso1}ï¼ˆJSTï¼‰ã§ã™ã€‚æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚"

            composed = guard + "\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æœ›: " + query
            summary = _summarize_with_citations(gc, composed, results, (data.get("model") or "").strip())

            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’ä¿å­˜
            reply = summary.get("answer") or summary.get("summary") or summary.get("text") or "æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
            db.session.commit()

            # åŒæœŸçš„ã«è¦ç´„ã‚’ç”Ÿæˆ
            _generate_summary_sync(cid)

            return jsonify({"ok": True, "conversation_id": cid, **summary})
        except GeminiFallbackError as e:
            logger.error(f"Search/Summarize path failed due to GeminiFallbackError: {e}")
            reply = f"æ¤œç´¢çµæœã®è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚„è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼: {e}"
            db.session.add(Message(content=reply, sender="assistant", conversation_id=cid))
            db.session.commit()
            return jsonify({"ok": True, "answer": reply, "citations": []})

    # ----------------- Export -----------------
    @bp.route("/api/export/<int:cid>")
    @login_required
    def export(cid: int):
        conv = Conversation.query.get(cid)
        if not conv:
            abort(404)
        if conv.user_id != current_user.id and not getattr(current_user, "is_admin", False):
            abort(403)
        messages = Message.query.filter_by(conversation_id=cid).all()
        return jsonify({
            "id": conv.id,
            "title": conv.title,
            "created_at": getattr(conv, "created_at", None).isoformat() if getattr(conv, "created_at", None) else "",
            "messages": [{"role": m.sender, "content": m.content} for m in messages]
        })

    # ----------------- Deep Research API -----------------
    @bp.route("/api/deep_research", methods=["POST"])
    @login_required
    @limiter.limit("100 per hour")  # Testing: Temporarily increased for development (TODO: restore to 5 per hour in production)
    def create_deep_research():
        """
        Create a new Deep Research job.
        Request: {query: str, conversation_id?: int}
        Response: {ok: true, job_id: int, status: str} or {ok: false, error: str}
        """
        data = request.get_json()
        query = data.get("query", "").strip()
        conversation_id = data.get("conversation_id")

        if not query:
            return jsonify({"ok": False, "error": "Query is required"}), 400

        # Check if Redis/RQ is available
        rq_queue = current_app.extensions.get("rq_queue")
        if rq_queue is None:
            return jsonify({
                "ok": False,
                "error": "Deep Research service is temporarily unavailable (background queue not available)"
            }), 503

        # Verify conversation ownership if conversation_id provided
        if conversation_id:
            conv = db.session.get(Conversation, conversation_id)
            if not conv or conv.user_id != current_user.id:
                return jsonify({"ok": False, "error": "Invalid conversation"}), 403

        try:
            # Import task function
            from services.tasks import execute_deep_research

            # Create ResearchJob record
            import uuid
            task_id = str(uuid.uuid4())

            job = ResearchJob(
                task_id=task_id,
                user_id=current_user.id,
                conversation_id=conversation_id,
                query=query,
                status="pending",
                phase="initializing",
                progress_message="ç ”ç©¶ã‚¸ãƒ§ãƒ–ã‚’åˆæœŸåŒ–ä¸­..."
            )
            db.session.add(job)
            db.session.flush()  # Flush to get job.id without committing

            # Enqueue RQ task (if this fails, rollback will happen in except block)
            rq_job = rq_queue.enqueue(
                execute_deep_research,
                job.id,
                job_timeout="20m"  # 20 minutes timeout (increased from 10m)
            )

            # Only commit after successful enqueue
            db.session.commit()

            logger.info(f"[DeepResearch] Created job {job.id} for user {current_user.id}, RQ job {rq_job.id}")

            return jsonify({
                "ok": True,
                "job_id": job.id,
                "status": job.status,
                "message": "Deep Research job created successfully"
            }), 201

        except Exception as e:
            db.session.rollback()
            logger.exception(f"[DeepResearch] Failed to create job: {e}")
            # Return generic error to prevent leaking internal details
            return jsonify({"ok": False, "error": "An unexpected error occurred while creating the research job."}), 500

    @bp.route("/api/deep_research/status/<int:job_id>", methods=["GET"])
    @login_required
    def get_deep_research_status(job_id: int):
        """
        Get status of a Deep Research job.
        Response: {ok: true, job_id, status, phase, progress_message, sources_count, sub_queries}
        """
        job = db.session.get(ResearchJob, job_id)

        # Ownership check (critical security requirement)
        if not job or job.user_id != current_user.id:
            abort(404)  # Use 404 to avoid leaking info about existing jobs

        response = jsonify({
            "ok": True,
            "job_id": job.id,
            "status": job.status,
            "phase": job.phase,
            "progress_message": job.progress_message,
            "sources_count": job.sources_count,
            "sub_queries": json.loads(job.sub_queries) if job.sub_queries else [],
            "created_at": job.created_at.isoformat() if job.created_at else None,
            "error": job.error_message if job.status == "failed" else None
        })
        # Prevent caching of polling responses
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        response.headers['Pragma'] = 'no-cache'
        return response

    @bp.route("/api/deep_research/result/<int:job_id>", methods=["GET"])
    @login_required
    def get_deep_research_result(job_id: int):
        """
        Get result of a completed Deep Research job.
        Response: {ok: true, job_id, status, result_report, ...} or error if not completed
        """
        job = db.session.get(ResearchJob, job_id)

        # Ownership check (critical security requirement)
        if not job or job.user_id != current_user.id:
            abort(404)  # Use 404 to avoid leaking info about existing jobs

        # State validation: only return result if completed
        if job.status != "completed":
            return jsonify({
                "ok": False,
                "error": f"Job is not completed yet (current status: {job.status})",
                "status": job.status,
                "phase": job.phase,
                "progress_message": job.progress_message
            }), 400

        return jsonify({
            "ok": True,
            "job_id": job.id,
            "status": job.status,
            "query": job.query,
            "result_report": job.result_report,
            "sources_count": job.sources_count,
            "sub_queries": json.loads(job.sub_queries) if job.sub_queries else [],
            "created_at": job.created_at.isoformat() if job.created_at else None,
            "completed_at": job.completed_at.isoformat() if job.completed_at else None
        })

    # ----------------- Error Handlers -----------------
    @bp.errorhandler(CSRFError)
    def handle_csrf(e):
        return jsonify({"ok": False, "error": "CSRF validation failed", "details": e.description}), 400

    @bp.errorhandler(Exception)
    def handle_exception(e):
        logger.exception("Unhandled error")
        return jsonify({"ok": False, "error": str(e)}), 500

    app.register_blueprint(bp)
    return app



